{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised methods\n",
    "\n",
    "In this lesson, we'll cover unsupervised computational text anlalysis approaches. The central methods covered are TF-IDF and Topic Modeling. Both of these are common approachs in the social sciences and humanities.\n",
    "\n",
    "[DTM/TF-IDF](#dtm)<br>\n",
    "\n",
    "[Topic modeling](#topics)<br>\n",
    "\n",
    "### Today you will\n",
    "* Understand the DTM and why it's important to text analysis\n",
    "* Learn how to create a DTM in Python\n",
    "* Learn basic functionality of Python's package scikit-learn\n",
    "* Understand tf-idf scores\n",
    "* Learn a simple way to identify distinctive words\n",
    "* Implement a basic topic modeling algorithm and learn how to tweak it\n",
    "* In the process, gain more familiarity and comfort with the Pandas package and manipulating data\n",
    "\n",
    "\n",
    "### Key Jargon\n",
    "* *Document Term Matrix*:\n",
    "    * a matrix that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms.\n",
    "* *TF-IDF Scores*: \n",
    "    * short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "* *Topic Modeling*:\n",
    "    * A general class of statistical models that uncover abstract topics within a text. It uses the co-occurrence of words within documents, compared to their distribution across documents, to uncover these abstract themes. The output is a list of weighted words, which indicate the subject of each topic, and a weight distribution across topics for each document.\n",
    "    \n",
    "* *LDA*:\n",
    "    * Latent Dirichlet Allocation. A particular model for topic modeling. It does not take document order into account, unlike other topic modeling algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM/TF-IDF <a id='dtm'></a>\n",
    "\n",
    "In this lesson we will use Python's scikit-learn package learn to make a document term matrix from a .csv Music Reviews dataset (collected from MetaCritic.com). We will then use the DTM and a word weighting technique called tf-idf (term frequency inverse document frequency) to identify important and discriminating words within this dataset (utilizing the Pandas package). The illustrating question: **what words distinguish reviews of Rap albums, Indie Rock albums, and Jazz albums?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "music_fname = 'music_reviews.csv'\n",
    "music_fname = os.path.join(DATA_DIR, music_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt at reading in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>critic</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-10-09 00:00:00</td>\n",
       "      <td>Kerrang!</td>\n",
       "      <td>74.0</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear and Saturday Night</td>\n",
       "      <td>Ryan Bingham</td>\n",
       "      <td>Country</td>\n",
       "      <td>2015-01-20 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>70.0</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way I'm Livin'</td>\n",
       "      <td>Lee Ann Womack</td>\n",
       "      <td>Country</td>\n",
       "      <td>2014-09-23 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>84.0</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris</td>\n",
       "      <td>Earl Sweatshirt</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2013-08-20 00:00:00</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>82.0</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giraffe</td>\n",
       "      <td>Echoboy</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2003-02-25 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     album           artist     genre         release_date  \\\n",
       "0              Don't Panic     All Time Low  Pop/Rock  2012-10-09 00:00:00   \n",
       "1  Fear and Saturday Night     Ryan Bingham   Country  2015-01-20 00:00:00   \n",
       "2       The Way I'm Livin'   Lee Ann Womack   Country  2014-09-23 00:00:00   \n",
       "3                    Doris  Earl Sweatshirt       Rap  2013-08-20 00:00:00   \n",
       "4                  Giraffe          Echoboy      Rock  2003-02-25 00:00:00   \n",
       "\n",
       "       critic  score                                               body  \n",
       "0    Kerrang!   74.0  While For Baltimore proves they can still writ...  \n",
       "1       Uncut   70.0  There's nothing fake about the purgatorial nar...  \n",
       "2  Q Magazine   84.0  All life's disastrous lows are here on a caree...  \n",
       "3   Pitchfork   82.0  With Doris, Odd Future’s Odysseus is finally b...  \n",
       "4    AllMusic   71.0  Though Giraffe is definitely Echoboy's most im...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(music_fname, sep='\\t')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the text of the first review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While For Baltimore proves they can still write a grade A banger when they put their mind to it, too many songs are destined to have \"must try harder\" stamped on their report card. [13 Oct 2012, p.52]\n"
     ]
    }
   ],
   "source": [
    "print(reviews['body'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data using Pandas\n",
    "\n",
    "Let's first look at some descriptive statistics about this dataset, to get a feel for what's in it. We'll do this using the Pandas package. \n",
    "\n",
    "Note: this is always good practice. It serves two purposes. It checks to make sure your data is correct, and there's no major errors. It also keeps you in touch with your data, which will help with interpretation. <3 your data!\n",
    "\n",
    "First, what genres are in this dataset, and how many reviews in each genre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop/Rock                  1486\n",
       "Indie                     1115\n",
       "Rock                       932\n",
       "Electronic                 513\n",
       "Rap                        363\n",
       "Pop                        149\n",
       "Country                    140\n",
       "R&B;                       112\n",
       "Folk                        70\n",
       "Alternative/Indie Rock      42\n",
       "Dance                       41\n",
       "Jazz                        38\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can count this using the value_counts() function\n",
    "reviews['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing most people do is to `describe` their data. (This is the `summary` command in R, or the `sum` command in Stata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>72.684223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.714896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             score\n",
       "count  5001.000000\n",
       "mean     72.684223\n",
       "std       8.714896\n",
       "min       7.400000\n",
       "25%      68.000000\n",
       "50%      74.000000\n",
       "75%      79.000000\n",
       "max     100.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There's only one numeric column in our data so we only get one column for output.\n",
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only gets us numerical summaries. To get summaries of some of the other columns, we can explicitly ask for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>critic</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3799</td>\n",
       "      <td>2607</td>\n",
       "      <td>12</td>\n",
       "      <td>956</td>\n",
       "      <td>592</td>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sumday</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2011-09-13 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>He does express regret about the marriage brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>1486</td>\n",
       "      <td>29</td>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         album           artist     genre         release_date    critic  \\\n",
       "count     5001             5001      5001                 5001      5001   \n",
       "unique    3799             2607        12                  956       592   \n",
       "top     Sumday  Various Artists  Pop/Rock  2011-09-13 00:00:00  AllMusic   \n",
       "freq         5               22      1486                   29       282   \n",
       "\n",
       "                                                     body  \n",
       "count                                                5001  \n",
       "unique                                               4998  \n",
       "top     He does express regret about the marriage brea...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who were the reviewers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllMusic                     282\n",
       "PopMatters                   228\n",
       "Pitchfork                    207\n",
       "Q Magazine                   178\n",
       "Uncut                        171\n",
       "Mojo                         137\n",
       "Drowned In Sound             132\n",
       "New Musical Express (NME)    127\n",
       "The A.V. Club                121\n",
       "Rolling Stone                112\n",
       "Name: critic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['critic'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the artists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Various Artists      22\n",
       "R.E.M.               16\n",
       "Arcade Fire          14\n",
       "Sigur Rós            13\n",
       "Belle & Sebastian    12\n",
       "Brian Eno            11\n",
       "Low                  10\n",
       "Radiohead            10\n",
       "Bob Dylan            10\n",
       "Kings of Leon        10\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['artist'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the average score as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.68422315536893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to know the average score for each genre? To do this, we use Pandas `groupby` function. You'll want to get very familiar with the `groupby` function. It's quite powerful. (Similar to `collapse` on Stata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Jazz                      77.631579\n",
       "Folk                      75.900000\n",
       "Indie                     74.400897\n",
       "Country                   74.071429\n",
       "Alternative/Indie Rock    73.928571\n",
       "Electronic                73.140351\n",
       "Pop/Rock                  73.033782\n",
       "R&B;                      72.366071\n",
       "Rap                       72.173554\n",
       "Rock                      70.754292\n",
       "Dance                     70.146341\n",
       "Pop                       64.608054\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_grouped_by_genre = reviews.groupby(\"genre\")\n",
    "reviews_grouped_by_genre['score'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the DTM using scikit-learn\n",
    "\n",
    "Ok, that's the summary of the metadata. Next, we turn to analyzing the text of the reviews. Remember, the text is stored in the 'body' column. First, a preprocessing step to remove numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>critic</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>body_without_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-10-09 00:00:00</td>\n",
       "      <td>Kerrang!</td>\n",
       "      <td>74.0</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear and Saturday Night</td>\n",
       "      <td>Ryan Bingham</td>\n",
       "      <td>Country</td>\n",
       "      <td>2015-01-20 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>70.0</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way I'm Livin'</td>\n",
       "      <td>Lee Ann Womack</td>\n",
       "      <td>Country</td>\n",
       "      <td>2014-09-23 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>84.0</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris</td>\n",
       "      <td>Earl Sweatshirt</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2013-08-20 00:00:00</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>82.0</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giraffe</td>\n",
       "      <td>Echoboy</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2003-02-25 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Weathervanes</td>\n",
       "      <td>Freelance Whales</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2010-04-13 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Fans of Owl City and The Postal Service will r...</td>\n",
       "      <td>Fans of Owl City and The Postal Service will r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Build a Rocket Boys!</td>\n",
       "      <td>Elbow</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2011-04-12 00:00:00</td>\n",
       "      <td>Delusions of Adequacy</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Whereas previous Elbow records set a mood, Bui...</td>\n",
       "      <td>Whereas previous Elbow records set a mood, Bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ambivalence Avenue</td>\n",
       "      <td>Bibio</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2009-06-23 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>78.0</td>\n",
       "      <td>His remarkable Warp debut follows a series of ...</td>\n",
       "      <td>His remarkable Warp debut follows a series of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wavvves</td>\n",
       "      <td>Wavves</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2009-03-17 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>68.0</td>\n",
       "      <td>There’s an energy coursing through this, and r...</td>\n",
       "      <td>There’s an energy coursing through this, and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Peachtree Road</td>\n",
       "      <td>Elton John</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2004-11-09 00:00:00</td>\n",
       "      <td>MelD.</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Classic. Songs filled with soul. Lyrics refres...</td>\n",
       "      <td>Classic. Songs filled with soul. Lyrics refres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Heritage</td>\n",
       "      <td>College</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>2013-09-17 00:00:00</td>\n",
       "      <td>musicOMH.com</td>\n",
       "      <td>63.0</td>\n",
       "      <td>It’s by no means perfect and it does feel slig...</td>\n",
       "      <td>It’s by no means perfect and it does feel slig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>White Chalk</td>\n",
       "      <td>PJ Harvey</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2007-09-25 00:00:00</td>\n",
       "      <td>Paste Magazine</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Put in context, White Chalk serves her purpose...</td>\n",
       "      <td>Put in context, White Chalk serves her purpose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tyrannosaurus Hives</td>\n",
       "      <td>The Hives</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2004-07-20 00:00:00</td>\n",
       "      <td>Playlouder</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Although pretty catchy, this album is a tad to...</td>\n",
       "      <td>Although pretty catchy, this album is a tad to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JackInABox</td>\n",
       "      <td>Turin Brakes</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2005-06-07 00:00:00</td>\n",
       "      <td>New Musical Express (NME)</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Talk about a fall from grace. [4 Jun 2005, p.58]</td>\n",
       "      <td>Talk about a fall from grace. [ Jun , p.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Liquid Love</td>\n",
       "      <td>Shy Child</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2010-03-15 00:00:00</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>70.0</td>\n",
       "      <td>It's unusual to find a band equally at home wi...</td>\n",
       "      <td>It's unusual to find a band equally at home wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The  Truth About Love</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>Pop</td>\n",
       "      <td>2012-09-18 00:00:00</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>77.0</td>\n",
       "      <td>It's just a shame she gave album space to Mari...</td>\n",
       "      <td>It's just a shame she gave album space to Mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Monitor</td>\n",
       "      <td>Titus Andronicus</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2010-03-09 00:00:00</td>\n",
       "      <td>Prefix Magazine</td>\n",
       "      <td>82.0</td>\n",
       "      <td>The fundamental difference between The Monitor...</td>\n",
       "      <td>The fundamental difference between The Monitor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ones and Sixes</td>\n",
       "      <td>Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2015-09-11 00:00:00</td>\n",
       "      <td>Consequence of Sound</td>\n",
       "      <td>78.0</td>\n",
       "      <td>It just needs to be a passionate, cathartic, c...</td>\n",
       "      <td>It just needs to be a passionate, cathartic, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>In Search Of... [First Version]</td>\n",
       "      <td>N.E.R.D. [The Neptunes]</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2001-08-06 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>92.0</td>\n",
       "      <td>They retained their best ideas for themselves ...</td>\n",
       "      <td>They retained their best ideas for themselves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tarot Sport</td>\n",
       "      <td>Fuck Buttons</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2009-10-20 00:00:00</td>\n",
       "      <td>The A.V. Club</td>\n",
       "      <td>84.0</td>\n",
       "      <td>For most of the songs amassed here, it still t...</td>\n",
       "      <td>For most of the songs amassed here, it still t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>July Flame</td>\n",
       "      <td>Laura Veirs</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2010-01-12 00:00:00</td>\n",
       "      <td>musicOMH.com</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Laura Veirs makes an excellent case for hersel...</td>\n",
       "      <td>Laura Veirs makes an excellent case for hersel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lux</td>\n",
       "      <td>Brian Eno</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>2012-11-13 00:00:00</td>\n",
       "      <td>Paste Magazine</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Sure, it's beautiful on its own, but without a...</td>\n",
       "      <td>Sure, it's beautiful on its own, but without a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Live At The Olympia</td>\n",
       "      <td>R.E.M.</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2009-10-27 00:00:00</td>\n",
       "      <td>The A.V. Club</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Though it isn’t a concept album, Live At The O...</td>\n",
       "      <td>Though it isn’t a concept album, Live At The O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ten Thousand Fists</td>\n",
       "      <td>Disturbed</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2005-09-20 00:00:00</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>59.0</td>\n",
       "      <td>The album isn't without its problems––come the...</td>\n",
       "      <td>The album isn't without its problems––come the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New Danger</td>\n",
       "      <td>Mos Def</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2004-10-12 00:00:00</td>\n",
       "      <td>Austin Chronicle</td>\n",
       "      <td>59.0</td>\n",
       "      <td>The New Danger is as overextended as it is sel...</td>\n",
       "      <td>The New Danger is as overextended as it is sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NYC</td>\n",
       "      <td>Kieran Hebden and Steve Reid</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2008-11-18 00:00:00</td>\n",
       "      <td>The Wire</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Hebden is clearly striving for dancefloor impa...</td>\n",
       "      <td>Hebden is clearly striving for dancefloor impa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hold On Now, Youngster</td>\n",
       "      <td>Los Campesinos!</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2008-04-01 00:00:00</td>\n",
       "      <td>Austin Chronicle</td>\n",
       "      <td>81.0</td>\n",
       "      <td>It might be one big, saccharine, catchy fuck-y...</td>\n",
       "      <td>It might be one big, saccharine, catchy fuck-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tiny Rebels [EP]</td>\n",
       "      <td>Cairo Gang</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2013-07-23 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>64.0</td>\n",
       "      <td>The Cairo Gang's superb, weighty, meticulous a...</td>\n",
       "      <td>The Cairo Gang's superb, weighty, meticulous a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wavering Radiant</td>\n",
       "      <td>Isis</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2009-05-05 00:00:00</td>\n",
       "      <td>No Ripcord</td>\n",
       "      <td>79.0</td>\n",
       "      <td>As snobbish as that may sound, you have to los...</td>\n",
       "      <td>As snobbish as that may sound, you have to los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sound Mirrors</td>\n",
       "      <td>Coldcut</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>2006-02-21 00:00:00</td>\n",
       "      <td>Playlouder</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Any number of tracks here could easily catapul...</td>\n",
       "      <td>Any number of tracks here could easily catapul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>This Machine Kills Artists</td>\n",
       "      <td>King Buzzo</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2014-06-03 00:00:00</td>\n",
       "      <td>The Line of Best Fit</td>\n",
       "      <td>69.0</td>\n",
       "      <td>It is an interesting experiment, but realistic...</td>\n",
       "      <td>It is an interesting experiment, but realistic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>The Fire Theft</td>\n",
       "      <td>The Fire Theft</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2003-09-23 00:00:00</td>\n",
       "      <td>Alternative Press</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Yes, it sounds like Yes, and, no, I don't mean...</td>\n",
       "      <td>Yes, it sounds like Yes, and, no, I don't mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>XI Versions of Black Noise</td>\n",
       "      <td>Pantha du Prince</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>2011-04-19 00:00:00</td>\n",
       "      <td>The Boston Phoenix</td>\n",
       "      <td>62.0</td>\n",
       "      <td>The pointlessness is grating. XI Versions' fin...</td>\n",
       "      <td>The pointlessness is grating. XI Versions' fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>I Dreamed We Fell Apart</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2004-09-21 00:00:00</td>\n",
       "      <td>Launch.com</td>\n",
       "      <td>67.0</td>\n",
       "      <td>The basic ingredients are delicate, minimal, w...</td>\n",
       "      <td>The basic ingredients are delicate, minimal, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>Beat Pyramid</td>\n",
       "      <td>These New Puritans</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2008-03-18 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Anyone bored by the kitchen sink will find muc...</td>\n",
       "      <td>Anyone bored by the kitchen sink will find muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>Freedom's Road</td>\n",
       "      <td>John Mellencamp</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2007-01-23 00:00:00</td>\n",
       "      <td>Blender</td>\n",
       "      <td>65.0</td>\n",
       "      <td>There are two vastly different Mellencamps. On...</td>\n",
       "      <td>There are two vastly different Mellencamps. On...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>Scott Pilgrim Vs. The World</td>\n",
       "      <td>Original Soundtrack</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2010-08-10 00:00:00</td>\n",
       "      <td>ImmersedInSound</td>\n",
       "      <td>68.0</td>\n",
       "      <td>The movie is incredible. Everything about it i...</td>\n",
       "      <td>The movie is incredible. Everything about it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>Little Neon Limelight</td>\n",
       "      <td>Houndmouth</td>\n",
       "      <td>Country</td>\n",
       "      <td>2015-03-17 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Houndmouth have the right touch and impressive...</td>\n",
       "      <td>Houndmouth have the right touch and impressive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>Hawk</td>\n",
       "      <td>Isobel Campbell</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2010-08-24 00:00:00</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Hawk is very much Campbell's album. She made a...</td>\n",
       "      <td>Hawk is very much Campbell's album. She made a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>Single Mothers</td>\n",
       "      <td>Justin Townes Earle</td>\n",
       "      <td>Country</td>\n",
       "      <td>2014-09-09 00:00:00</td>\n",
       "      <td>The A.V. Club</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Earle’s consistency is both his friend and his...</td>\n",
       "      <td>Earle’s consistency is both his friend and his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>Lost Horizons</td>\n",
       "      <td>Lemon Jelly</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>2002-10-08 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Think early Air meets hip-hop, the West Coast ...</td>\n",
       "      <td>Think early Air meets hip-hop, the West Coast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>Dry Land is Not a Myth</td>\n",
       "      <td>White Arrows</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-06-19 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>70.0</td>\n",
       "      <td>A certain kind of playfulness reigns throughou...</td>\n",
       "      <td>A certain kind of playfulness reigns throughou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>Pain Killer</td>\n",
       "      <td>Little Big Town</td>\n",
       "      <td>Country</td>\n",
       "      <td>2014-10-21 00:00:00</td>\n",
       "      <td>joyel1992</td>\n",
       "      <td>83.0</td>\n",
       "      <td>One of the best country album Ive heard in a w...</td>\n",
       "      <td>One of the best country album Ive heard in a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>Swing Lo Magellan</td>\n",
       "      <td>Dirty Projectors</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-07-10 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>80.0</td>\n",
       "      <td>What really shines through the most on Magella...</td>\n",
       "      <td>What really shines through the most on Magella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>Maraqopa</td>\n",
       "      <td>Damien Jurado</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-02-20 00:00:00</td>\n",
       "      <td>Beats Per Minute (formerly One Thirty BPM)</td>\n",
       "      <td>81.0</td>\n",
       "      <td>These songs are probably Jurado's most ambitio...</td>\n",
       "      <td>These songs are probably Jurado's most ambitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>Son</td>\n",
       "      <td>Juana Molina</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2006-06-06 00:00:00</td>\n",
       "      <td>The Wire</td>\n",
       "      <td>79.0</td>\n",
       "      <td>What's distinctive about Son is that it is mor...</td>\n",
       "      <td>What's distinctive about Son is that it is mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>Holiday</td>\n",
       "      <td>Port St. Willow</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2013-04-02 00:00:00</td>\n",
       "      <td>musicOMH.com</td>\n",
       "      <td>80.0</td>\n",
       "      <td>At times this recording is compelling, entranc...</td>\n",
       "      <td>At times this recording is compelling, entranc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>Majenta</td>\n",
       "      <td>Jimmy Edgar</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>2012-12-04 00:00:00</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Unfortunately, more than mediocre tracks or th...</td>\n",
       "      <td>Unfortunately, more than mediocre tracks or th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>Love Is Here</td>\n",
       "      <td>Starsailor</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2002-01-08 00:00:00</td>\n",
       "      <td>Screenager</td>\n",
       "      <td>72.0</td>\n",
       "      <td>A beautifully crafted debut album and one of t...</td>\n",
       "      <td>A beautifully crafted debut album and one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>Days</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2011-10-18 00:00:00</td>\n",
       "      <td>Blurt Magazine</td>\n",
       "      <td>77.0</td>\n",
       "      <td>A fine batch of bittersweet pop songs that are...</td>\n",
       "      <td>A fine batch of bittersweet pop songs that are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>Rebirth</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2010-02-02 00:00:00</td>\n",
       "      <td>No Ripcord</td>\n",
       "      <td>37.0</td>\n",
       "      <td>The derivativeness quickly overwhelms.</td>\n",
       "      <td>The derivativeness quickly overwhelms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>Blue Songs</td>\n",
       "      <td>Hercules &amp; Love Affair</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>2011-08-16 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Blue Songs finds Butler and his crew of collab...</td>\n",
       "      <td>Blue Songs finds Butler and his crew of collab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>England, Half English</td>\n",
       "      <td>Billy Bragg</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2002-03-05 00:00:00</td>\n",
       "      <td>Spin</td>\n",
       "      <td>64.0</td>\n",
       "      <td>England's exoticism is offset by plenty of tou...</td>\n",
       "      <td>England's exoticism is offset by plenty of tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>Weezer (Red Album)</td>\n",
       "      <td>Weezer</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2008-06-03 00:00:00</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Weezer seems to have driven their old shtick i...</td>\n",
       "      <td>Weezer seems to have driven their old shtick i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Dreams and Nightmares</td>\n",
       "      <td>Meek Mill</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2012-10-30 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>69.0</td>\n",
       "      <td>As far as graduations from mixtapes to major-l...</td>\n",
       "      <td>As far as graduations from mixtapes to major-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Outer South</td>\n",
       "      <td>Conor Oberst And The Mystic Valley Band</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2009-05-05 00:00:00</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>67.0</td>\n",
       "      <td>The result is an album that's unfortunately ba...</td>\n",
       "      <td>The result is an album that's unfortunately ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>On An Island</td>\n",
       "      <td>David Gilmour</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2006-03-07 00:00:00</td>\n",
       "      <td>E! Online</td>\n",
       "      <td>67.0</td>\n",
       "      <td>In the end, Island makes Dave sound like he's ...</td>\n",
       "      <td>In the end, Island makes Dave sound like he's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Movement</td>\n",
       "      <td>Gossip</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2003-05-06 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Beth Ditto's remarkable gospel holler and ferv...</td>\n",
       "      <td>Beth Ditto's remarkable gospel holler and ferv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Locked Down</td>\n",
       "      <td>Dr. John</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-04-03 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Dr. John is Dr. John. He's a star, and is on f...</td>\n",
       "      <td>Dr. John is Dr. John. He's a star, and is on f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>And Their Refinement Of The Decline</td>\n",
       "      <td>Stars Of The Lid</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2007-04-07 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Their work, especially that displayed on Refin...</td>\n",
       "      <td>Their work, especially that displayed on Refin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    album  \\\n",
       "0                             Don't Panic   \n",
       "1                 Fear and Saturday Night   \n",
       "2                      The Way I'm Livin'   \n",
       "3                                   Doris   \n",
       "4                                 Giraffe   \n",
       "5                            Weathervanes   \n",
       "6                    Build a Rocket Boys!   \n",
       "7                      Ambivalence Avenue   \n",
       "8                                 Wavvves   \n",
       "9                          Peachtree Road   \n",
       "10                               Heritage   \n",
       "11                            White Chalk   \n",
       "12                    Tyrannosaurus Hives   \n",
       "13                             JackInABox   \n",
       "14                            Liquid Love   \n",
       "15                  The  Truth About Love   \n",
       "16                            The Monitor   \n",
       "17                         Ones and Sixes   \n",
       "18        In Search Of... [First Version]   \n",
       "19                            Tarot Sport   \n",
       "20                             July Flame   \n",
       "21                                    Lux   \n",
       "22                    Live At The Olympia   \n",
       "23                     Ten Thousand Fists   \n",
       "24                             New Danger   \n",
       "25                                    NYC   \n",
       "26                 Hold On Now, Youngster   \n",
       "27                       Tiny Rebels [EP]   \n",
       "28                       Wavering Radiant   \n",
       "29                          Sound Mirrors   \n",
       "...                                   ...   \n",
       "4971           This Machine Kills Artists   \n",
       "4972                       The Fire Theft   \n",
       "4973           XI Versions of Black Noise   \n",
       "4974              I Dreamed We Fell Apart   \n",
       "4975                         Beat Pyramid   \n",
       "4976                       Freedom's Road   \n",
       "4977          Scott Pilgrim Vs. The World   \n",
       "4978                Little Neon Limelight   \n",
       "4979                                 Hawk   \n",
       "4980                       Single Mothers   \n",
       "4981                        Lost Horizons   \n",
       "4982               Dry Land is Not a Myth   \n",
       "4983                          Pain Killer   \n",
       "4984                    Swing Lo Magellan   \n",
       "4985                             Maraqopa   \n",
       "4986                                  Son   \n",
       "4987                              Holiday   \n",
       "4988                              Majenta   \n",
       "4989                         Love Is Here   \n",
       "4990                                 Days   \n",
       "4991                              Rebirth   \n",
       "4992                           Blue Songs   \n",
       "4993                England, Half English   \n",
       "4994                   Weezer (Red Album)   \n",
       "4995                Dreams and Nightmares   \n",
       "4996                          Outer South   \n",
       "4997                         On An Island   \n",
       "4998                             Movement   \n",
       "4999                          Locked Down   \n",
       "5000  And Their Refinement Of The Decline   \n",
       "\n",
       "                                       artist       genre  \\\n",
       "0                                All Time Low    Pop/Rock   \n",
       "1                                Ryan Bingham     Country   \n",
       "2                              Lee Ann Womack     Country   \n",
       "3                             Earl Sweatshirt         Rap   \n",
       "4                                     Echoboy        Rock   \n",
       "5                            Freelance Whales       Indie   \n",
       "6                                       Elbow    Pop/Rock   \n",
       "7                                       Bibio       Indie   \n",
       "8                                      Wavves       Indie   \n",
       "9                                  Elton John        Rock   \n",
       "10                                    College  Electronic   \n",
       "11                                  PJ Harvey        Rock   \n",
       "12                                  The Hives        Rock   \n",
       "13                               Turin Brakes       Indie   \n",
       "14                                  Shy Child       Indie   \n",
       "15                                       P!nk         Pop   \n",
       "16                           Titus Andronicus       Indie   \n",
       "17                                        Low    Pop/Rock   \n",
       "18                    N.E.R.D. [The Neptunes]         Rap   \n",
       "19                               Fuck Buttons        Rock   \n",
       "20                                Laura Veirs       Indie   \n",
       "21                                  Brian Eno  Electronic   \n",
       "22                                     R.E.M.        Rock   \n",
       "23                                  Disturbed        Rock   \n",
       "24                                    Mos Def         Rap   \n",
       "25               Kieran Hebden and Steve Reid       Indie   \n",
       "26                            Los Campesinos!       Indie   \n",
       "27                                 Cairo Gang    Pop/Rock   \n",
       "28                                       Isis        Rock   \n",
       "29                                    Coldcut  Electronic   \n",
       "...                                       ...         ...   \n",
       "4971                               King Buzzo    Pop/Rock   \n",
       "4972                           The Fire Theft       Indie   \n",
       "4973                         Pantha du Prince  Electronic   \n",
       "4974                                  Memphis       Indie   \n",
       "4975                       These New Puritans        Rock   \n",
       "4976                          John Mellencamp        Rock   \n",
       "4977                      Original Soundtrack        Rock   \n",
       "4978                               Houndmouth     Country   \n",
       "4979                          Isobel Campbell    Pop/Rock   \n",
       "4980                      Justin Townes Earle     Country   \n",
       "4981                              Lemon Jelly  Electronic   \n",
       "4982                             White Arrows    Pop/Rock   \n",
       "4983                          Little Big Town     Country   \n",
       "4984                         Dirty Projectors    Pop/Rock   \n",
       "4985                            Damien Jurado    Pop/Rock   \n",
       "4986                             Juana Molina       Indie   \n",
       "4987                          Port St. Willow    Pop/Rock   \n",
       "4988                              Jimmy Edgar  Electronic   \n",
       "4989                               Starsailor        Rock   \n",
       "4990                              Real Estate    Pop/Rock   \n",
       "4991                                Lil Wayne         Rap   \n",
       "4992                   Hercules & Love Affair  Electronic   \n",
       "4993                              Billy Bragg        Rock   \n",
       "4994                                   Weezer        Rock   \n",
       "4995                                Meek Mill         Rap   \n",
       "4996  Conor Oberst And The Mystic Valley Band       Indie   \n",
       "4997                            David Gilmour        Rock   \n",
       "4998                                   Gossip       Indie   \n",
       "4999                                 Dr. John    Pop/Rock   \n",
       "5000                         Stars Of The Lid        Rock   \n",
       "\n",
       "             release_date                                      critic  score  \\\n",
       "0     2012-10-09 00:00:00                                    Kerrang!   74.0   \n",
       "1     2015-01-20 00:00:00                                       Uncut   70.0   \n",
       "2     2014-09-23 00:00:00                                  Q Magazine   84.0   \n",
       "3     2013-08-20 00:00:00                                   Pitchfork   82.0   \n",
       "4     2003-02-25 00:00:00                                    AllMusic   71.0   \n",
       "5     2010-04-13 00:00:00                                  Q Magazine   68.0   \n",
       "6     2011-04-12 00:00:00                       Delusions of Adequacy   82.0   \n",
       "7     2009-06-23 00:00:00                                  Q Magazine   78.0   \n",
       "8     2009-03-17 00:00:00                                  PopMatters   68.0   \n",
       "9     2004-11-09 00:00:00                                       MelD.   70.0   \n",
       "10    2013-09-17 00:00:00                                musicOMH.com   63.0   \n",
       "11    2007-09-25 00:00:00                              Paste Magazine   80.0   \n",
       "12    2004-07-20 00:00:00                                  Playlouder   78.0   \n",
       "13    2005-06-07 00:00:00                   New Musical Express (NME)   62.0   \n",
       "14    2010-03-15 00:00:00                                The Guardian   70.0   \n",
       "15    2012-09-18 00:00:00                                The Guardian   77.0   \n",
       "16    2010-03-09 00:00:00                             Prefix Magazine   82.0   \n",
       "17    2015-09-11 00:00:00                        Consequence of Sound   78.0   \n",
       "18    2001-08-06 00:00:00                                  Q Magazine   92.0   \n",
       "19    2009-10-20 00:00:00                               The A.V. Club   84.0   \n",
       "20    2010-01-12 00:00:00                                musicOMH.com   81.0   \n",
       "21    2012-11-13 00:00:00                              Paste Magazine   75.0   \n",
       "22    2009-10-27 00:00:00                               The A.V. Club   74.0   \n",
       "23    2005-09-20 00:00:00                                  Amazon.com   59.0   \n",
       "24    2004-10-12 00:00:00                            Austin Chronicle   59.0   \n",
       "25    2008-11-18 00:00:00                                    The Wire   61.0   \n",
       "26    2008-04-01 00:00:00                            Austin Chronicle   81.0   \n",
       "27    2013-07-23 00:00:00                                       Uncut   64.0   \n",
       "28    2009-05-05 00:00:00                                  No Ripcord   79.0   \n",
       "29    2006-02-21 00:00:00                                  Playlouder   73.0   \n",
       "...                   ...                                         ...    ...   \n",
       "4971  2014-06-03 00:00:00                        The Line of Best Fit   69.0   \n",
       "4972  2003-09-23 00:00:00                           Alternative Press   63.0   \n",
       "4973  2011-04-19 00:00:00                          The Boston Phoenix   62.0   \n",
       "4974  2004-09-21 00:00:00                                  Launch.com   67.0   \n",
       "4975  2008-03-18 00:00:00                                  Q Magazine   76.0   \n",
       "4976  2007-01-23 00:00:00                                     Blender   65.0   \n",
       "4977  2010-08-10 00:00:00                             ImmersedInSound   68.0   \n",
       "4978  2015-03-17 00:00:00                                    AllMusic   74.0   \n",
       "4979  2010-08-24 00:00:00                                   Pitchfork   75.0   \n",
       "4980  2014-09-09 00:00:00                               The A.V. Club   73.0   \n",
       "4981  2002-10-08 00:00:00                                       Uncut   81.0   \n",
       "4982  2012-06-19 00:00:00                                    AllMusic   70.0   \n",
       "4983  2014-10-21 00:00:00                                   joyel1992   83.0   \n",
       "4984  2012-07-10 00:00:00                                  PopMatters   80.0   \n",
       "4985  2012-02-20 00:00:00  Beats Per Minute (formerly One Thirty BPM)   81.0   \n",
       "4986  2006-06-06 00:00:00                                    The Wire   79.0   \n",
       "4987  2013-04-02 00:00:00                                musicOMH.com   80.0   \n",
       "4988  2012-12-04 00:00:00                                   Pitchfork   59.0   \n",
       "4989  2002-01-08 00:00:00                                  Screenager   72.0   \n",
       "4990  2011-10-18 00:00:00                              Blurt Magazine   77.0   \n",
       "4991  2010-02-02 00:00:00                                  No Ripcord   37.0   \n",
       "4992  2011-08-16 00:00:00                                  PopMatters   68.0   \n",
       "4993  2002-03-05 00:00:00                                        Spin   64.0   \n",
       "4994  2008-06-03 00:00:00                              Slant Magazine   64.0   \n",
       "4995  2012-10-30 00:00:00                                    AllMusic   69.0   \n",
       "4996  2009-05-05 00:00:00                              Slant Magazine   67.0   \n",
       "4997  2006-03-07 00:00:00                                   E! Online   67.0   \n",
       "4998  2003-05-06 00:00:00                                       Uncut   81.0   \n",
       "4999  2012-04-03 00:00:00                                  PopMatters   86.0   \n",
       "5000  2007-04-07 00:00:00                                  PopMatters   87.0   \n",
       "\n",
       "                                                   body  \\\n",
       "0     While For Baltimore proves they can still writ...   \n",
       "1     There's nothing fake about the purgatorial nar...   \n",
       "2     All life's disastrous lows are here on a caree...   \n",
       "3     With Doris, Odd Future’s Odysseus is finally b...   \n",
       "4     Though Giraffe is definitely Echoboy's most im...   \n",
       "5     Fans of Owl City and The Postal Service will r...   \n",
       "6     Whereas previous Elbow records set a mood, Bui...   \n",
       "7     His remarkable Warp debut follows a series of ...   \n",
       "8     There’s an energy coursing through this, and r...   \n",
       "9     Classic. Songs filled with soul. Lyrics refres...   \n",
       "10    It’s by no means perfect and it does feel slig...   \n",
       "11    Put in context, White Chalk serves her purpose...   \n",
       "12    Although pretty catchy, this album is a tad to...   \n",
       "13     Talk about a fall from grace. [4 Jun 2005, p.58]   \n",
       "14    It's unusual to find a band equally at home wi...   \n",
       "15    It's just a shame she gave album space to Mari...   \n",
       "16    The fundamental difference between The Monitor...   \n",
       "17    It just needs to be a passionate, cathartic, c...   \n",
       "18    They retained their best ideas for themselves ...   \n",
       "19    For most of the songs amassed here, it still t...   \n",
       "20    Laura Veirs makes an excellent case for hersel...   \n",
       "21    Sure, it's beautiful on its own, but without a...   \n",
       "22    Though it isn’t a concept album, Live At The O...   \n",
       "23    The album isn't without its problems––come the...   \n",
       "24    The New Danger is as overextended as it is sel...   \n",
       "25    Hebden is clearly striving for dancefloor impa...   \n",
       "26    It might be one big, saccharine, catchy fuck-y...   \n",
       "27    The Cairo Gang's superb, weighty, meticulous a...   \n",
       "28    As snobbish as that may sound, you have to los...   \n",
       "29    Any number of tracks here could easily catapul...   \n",
       "...                                                 ...   \n",
       "4971  It is an interesting experiment, but realistic...   \n",
       "4972  Yes, it sounds like Yes, and, no, I don't mean...   \n",
       "4973  The pointlessness is grating. XI Versions' fin...   \n",
       "4974  The basic ingredients are delicate, minimal, w...   \n",
       "4975  Anyone bored by the kitchen sink will find muc...   \n",
       "4976  There are two vastly different Mellencamps. On...   \n",
       "4977  The movie is incredible. Everything about it i...   \n",
       "4978  Houndmouth have the right touch and impressive...   \n",
       "4979  Hawk is very much Campbell's album. She made a...   \n",
       "4980  Earle’s consistency is both his friend and his...   \n",
       "4981  Think early Air meets hip-hop, the West Coast ...   \n",
       "4982  A certain kind of playfulness reigns throughou...   \n",
       "4983  One of the best country album Ive heard in a w...   \n",
       "4984  What really shines through the most on Magella...   \n",
       "4985  These songs are probably Jurado's most ambitio...   \n",
       "4986  What's distinctive about Son is that it is mor...   \n",
       "4987  At times this recording is compelling, entranc...   \n",
       "4988  Unfortunately, more than mediocre tracks or th...   \n",
       "4989  A beautifully crafted debut album and one of t...   \n",
       "4990  A fine batch of bittersweet pop songs that are...   \n",
       "4991             The derivativeness quickly overwhelms.   \n",
       "4992  Blue Songs finds Butler and his crew of collab...   \n",
       "4993  England's exoticism is offset by plenty of tou...   \n",
       "4994  Weezer seems to have driven their old shtick i...   \n",
       "4995  As far as graduations from mixtapes to major-l...   \n",
       "4996  The result is an album that's unfortunately ba...   \n",
       "4997  In the end, Island makes Dave sound like he's ...   \n",
       "4998  Beth Ditto's remarkable gospel holler and ferv...   \n",
       "4999  Dr. John is Dr. John. He's a star, and is on f...   \n",
       "5000  Their work, especially that displayed on Refin...   \n",
       "\n",
       "                                    body_without_digits  \n",
       "0     While For Baltimore proves they can still writ...  \n",
       "1     There's nothing fake about the purgatorial nar...  \n",
       "2     All life's disastrous lows are here on a caree...  \n",
       "3     With Doris, Odd Future’s Odysseus is finally b...  \n",
       "4     Though Giraffe is definitely Echoboy's most im...  \n",
       "5     Fans of Owl City and The Postal Service will r...  \n",
       "6     Whereas previous Elbow records set a mood, Bui...  \n",
       "7     His remarkable Warp debut follows a series of ...  \n",
       "8     There’s an energy coursing through this, and r...  \n",
       "9     Classic. Songs filled with soul. Lyrics refres...  \n",
       "10    It’s by no means perfect and it does feel slig...  \n",
       "11    Put in context, White Chalk serves her purpose...  \n",
       "12    Although pretty catchy, this album is a tad to...  \n",
       "13            Talk about a fall from grace. [ Jun , p.]  \n",
       "14    It's unusual to find a band equally at home wi...  \n",
       "15    It's just a shame she gave album space to Mari...  \n",
       "16    The fundamental difference between The Monitor...  \n",
       "17    It just needs to be a passionate, cathartic, c...  \n",
       "18    They retained their best ideas for themselves ...  \n",
       "19    For most of the songs amassed here, it still t...  \n",
       "20    Laura Veirs makes an excellent case for hersel...  \n",
       "21    Sure, it's beautiful on its own, but without a...  \n",
       "22    Though it isn’t a concept album, Live At The O...  \n",
       "23    The album isn't without its problems––come the...  \n",
       "24    The New Danger is as overextended as it is sel...  \n",
       "25    Hebden is clearly striving for dancefloor impa...  \n",
       "26    It might be one big, saccharine, catchy fuck-y...  \n",
       "27    The Cairo Gang's superb, weighty, meticulous a...  \n",
       "28    As snobbish as that may sound, you have to los...  \n",
       "29    Any number of tracks here could easily catapul...  \n",
       "...                                                 ...  \n",
       "4971  It is an interesting experiment, but realistic...  \n",
       "4972  Yes, it sounds like Yes, and, no, I don't mean...  \n",
       "4973  The pointlessness is grating. XI Versions' fin...  \n",
       "4974  The basic ingredients are delicate, minimal, w...  \n",
       "4975  Anyone bored by the kitchen sink will find muc...  \n",
       "4976  There are two vastly different Mellencamps. On...  \n",
       "4977  The movie is incredible. Everything about it i...  \n",
       "4978  Houndmouth have the right touch and impressive...  \n",
       "4979  Hawk is very much Campbell's album. She made a...  \n",
       "4980  Earle’s consistency is both his friend and his...  \n",
       "4981  Think early Air meets hip-hop, the West Coast ...  \n",
       "4982  A certain kind of playfulness reigns throughou...  \n",
       "4983  One of the best country album Ive heard in a w...  \n",
       "4984  What really shines through the most on Magella...  \n",
       "4985  These songs are probably Jurado's most ambitio...  \n",
       "4986  What's distinctive about Son is that it is mor...  \n",
       "4987  At times this recording is compelling, entranc...  \n",
       "4988  Unfortunately, more than mediocre tracks or th...  \n",
       "4989  A beautifully crafted debut album and one of t...  \n",
       "4990  A fine batch of bittersweet pop songs that are...  \n",
       "4991             The derivativeness quickly overwhelms.  \n",
       "4992  Blue Songs finds Butler and his crew of collab...  \n",
       "4993  England's exoticism is offset by plenty of tou...  \n",
       "4994  Weezer seems to have driven their old shtick i...  \n",
       "4995  As far as graduations from mixtapes to major-l...  \n",
       "4996  The result is an album that's unfortunately ba...  \n",
       "4997  In the end, Island makes Dave sound like he's ...  \n",
       "4998  Beth Ditto's remarkable gospel holler and ferv...  \n",
       "4999  Dr. John is Dr. John. He's a star, and is on f...  \n",
       "5000  Their work, especially that displayed on Refin...  \n",
       "\n",
       "[5001 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_digits(comment):\n",
    "    return ''.join([ch for ch in comment if not ch.isdigit()])\n",
    "\n",
    "reviews['body_without_digits'] = reviews['body'].apply(remove_digits)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    While For Baltimore proves they can still writ...\n",
       "1    There's nothing fake about the purgatorial nar...\n",
       "2    All life's disastrous lows are here on a caree...\n",
       "3    With Doris, Odd Future’s Odysseus is finally b...\n",
       "4    Though Giraffe is definitely Echoboy's most im...\n",
       "Name: body_without_digits, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['body_without_digits'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer Function\n",
    "\n",
    "Our next step is to turn the text into a document term matrix using the scikit-learn function called `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "sparse_dtm = countvec.fit_transform(reviews['body_without_digits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We made a DTM! Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5001x16139 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 124340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is called Compressed Sparse Format. It save a lot of memory to store the dtm in this format, but it is difficult to look at for a human. To illustrate the techniques in this lesson we will first convert this matrix back to a Pandas DataFrame, a format we're more familiar with. For larger datasets, you will have to use the Compressed Sparse Format. Putting it into a DataFrame, however, will enable us to get more comfortable with Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaa  aahs  aaliyah  aaron  ab  abandon  abandoned  abandoning  abc  \\\n",
       "0   0     0     0        0      0   0        0          0           0    0   \n",
       "1   0     0     0        0      0   0        0          0           0    0   \n",
       "2   0     0     0        0      0   0        0          0           0    0   \n",
       "3   0     0     0        0      0   0        0          0           0    0   \n",
       "4   0     0     0        0      0   0        0          0           0    0   \n",
       "\n",
       "   ...   zone  zones  zoo  zooey  zoomer  zu  zydeco  álbum  être  über  \n",
       "0  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "1  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "2  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "3  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "4  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "\n",
       "[5 rows x 16139 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame(sparse_dtm.toarray(), columns=countvec.get_feature_names(), index=reviews.index)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we do with a DTM?\n",
    "\n",
    "We can quickly identify the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      7406\n",
       "and      4557\n",
       "of       4400\n",
       "to       3175\n",
       "is       2914\n",
       "it       2608\n",
       "that     2039\n",
       "in       1775\n",
       "album    1719\n",
       "this     1518\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge - SOLUTION\n",
    "\n",
    "* Print out the most infrequent words rather than the most frequent words. You can look at the [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#api-dataframe-stats) for more information.\n",
    "* Print the average number of times each word is used in a review.\n",
    "* Print this out sorted from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sincerest       1\n",
       "glyn            1\n",
       "gluttonously    1\n",
       "glue            1\n",
       "glows           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.sum().sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    1.480904\n",
       "and    0.911218\n",
       "of     0.879824\n",
       "to     0.634873\n",
       "is     0.582683\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.mean().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF scores\n",
    "\n",
    "How to find distinctive words in a corpus is a long-standing question in text analysis. Today, we'll learn one simple approach to this: TF-IDF. The idea behind words scores is to weight words not just by their frequency, but by their frequency in one document compared to their distribution across all documents. Words that are frequent, but are also used in every single document, will not be distinguising. We want to identify words that are unevenly distributed across the corpus.\n",
    "\n",
    "One of the most popular ways to weight words (beyond frequency counts) is `tf-idf score`. By offsetting the frequency of a word by its document frequency (the number of documents in which it appears) will in theory filter out common terms such as 'the', 'of', and 'and'.\n",
    "\n",
    "Traditionally, the *inverse document frequency* of word $j$ is calculated as:\n",
    "\n",
    "$idf_{j} = log\\left(\\frac{\\#docs}{\\#docs\\,with\\,j}\\right)$ \n",
    "\n",
    "and the *term freqency - inverse document frequency* is \n",
    "\n",
    "$tfidf_{ij} = f_{ij}\\times{idf_j}$ where $f_{ij}$ is the number of occurences of word $j$ in document $i$.\n",
    "\n",
    "You can, and often should, normalize the word frequency: \n",
    "\n",
    "$tfidf_{ij} = \\frac{f_{ij}}{\\#words\\,in\\,doc\\,i}\\times{idf_{j}}$\n",
    "\n",
    "We can calculate this manually, but scikit-learn has a built-in function to do so. This function also uses log frequencies, so the numbers will not correspond excactly to the calculations above. We'll use the [scikit-learn calculation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), but a challenge for you: use Pandas to calculate this manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDFVectorizer Function\n",
    "\n",
    "To do so, we simply do the same thing we did above with CountVectorizer, but instead we use the function TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gregor von Richthof\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<5001x16139 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 124340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvec = TfidfVectorizer()\n",
    "sparse_tfidf = tfidfvec.fit_transform(reviews['body_without_digits'])\n",
    "sparse_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaa  aahs  aaliyah  aaron   ab  abandon  abandoned  abandoning  abc  \\\n",
       "0  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "1  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "2  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "3  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "4  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "\n",
       "   ...   zone  zones  zoo  zooey  zoomer   zu  zydeco  álbum  être  über  \n",
       "0  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "1  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "2  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "3  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "4  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 16139 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pd.DataFrame(sparse_tfidf.toarray(), columns=tfidfvec.get_feature_names(), index=reviews.index)\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the 20 words with highest tf-idf weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brill         1.000000\n",
       "perfect       1.000000\n",
       "yummy         1.000000\n",
       "pppperfect    1.000000\n",
       "awesome       1.000000\n",
       "wonderfull    1.000000\n",
       "meh           1.000000\n",
       "stars         1.000000\n",
       "subpar        0.959257\n",
       "ga            0.908259\n",
       "masterful     0.898620\n",
       "grower        0.888624\n",
       "likable       0.867803\n",
       "acirc         0.867003\n",
       "great         0.864253\n",
       "infectious    0.859996\n",
       "blank         0.854475\n",
       "thrilling     0.848810\n",
       "smart         0.847852\n",
       "stuff         0.834479\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.max().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! We have successfully identified content words, without removing stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Distinctive Words\n",
    "\n",
    "What can we do with this? These scores are best used when you want to identify distinctive words for individual documents, or groups of documents, compared to other groups or the corpus as a whole. To illustrate this, let's compare three genres and identify the most distinctive words by genre.\n",
    "\n",
    "First we add in a column of genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "      <th>genre_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pop/Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaa  aahs  aaliyah  aaron   ab  abandon  abandoned  abandoning  abc  \\\n",
       "0  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "1  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "2  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "3  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "4  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "\n",
       "     ...     zones  zoo  zooey  zoomer   zu  zydeco  álbum  être  über  \\\n",
       "0    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "1    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "2    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "3    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "4    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "\n",
       "     genre_  \n",
       "0  Pop/Rock  \n",
       "1   Country  \n",
       "2   Country  \n",
       "3       Rap  \n",
       "4      Rock  \n",
       "\n",
       "[5 rows x 16140 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf['genre_'] = reviews['genre']\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compare the words with the highest tf-idf weight for each genre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blank        0.854475\n",
       "waste        0.755918\n",
       "amiable      0.730963\n",
       "awesomely    0.717079\n",
       "joyless      0.687687\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap = tfidf[tfidf['genre_']=='Rap']\n",
    "indie = tfidf[tfidf['genre_']=='Indie']\n",
    "jazz = tfidf[tfidf['genre_']=='Jazz']\n",
    "\n",
    "rap.max(numeric_only=True).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meh           1.0\n",
       "awesome       1.0\n",
       "wonderfull    1.0\n",
       "perfect       1.0\n",
       "yummy         1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indie.max(numeric_only=True).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "purely        0.544477\n",
       "descending    0.519218\n",
       "devotional    0.507724\n",
       "recordings    0.499963\n",
       "languid       0.487715\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz.max(numeric_only=True).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! A method of identifying distinctive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge - SOLUTION\n",
    "\n",
    "Instead of outputting the highest weighted words, output the lowest weighted words. How should we interpret these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aa             0.0\n",
       "potent         0.0\n",
       "potential      0.0\n",
       "potentially    0.0\n",
       "potion         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz.max(numeric_only=True).sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling <a id='topics'></a>\n",
    "\n",
    "The goal of topic models can be twofold: 1/ learning something about the topics themselves, i.e what the the ext is about 2/ reduce the dimensionality of text to represent a document as a weighted average of K topics instead of a vector of token counts over the whole vocabulary. In the latter case, topic modeling a way to treat text as any data in a more tractable way for any subsequent statistical analysis (linear/logistic regression, etc). \n",
    "\n",
    "There are many topic modeling algorithms, but we'll use LDA. This is a standard model to use. Again, the goal is not to learn everything you need to know about topic modeling. Instead, this will provide you some starter code to run a simple model, with the idea that you can use this base of knowledge to explore this further.\n",
    "\n",
    "We will run Latent Dirichlet Allocation, the most basic and the oldest version of topic modeling$^1$. We will run this in one big chunk of code. Our challenge: use our knowledge of scikit-learn that we gained above to walk through the code to understand what it is doing. Your challenge: figure out how to modify this code to work on your own data, and/or tweak the parameters to get better output.\n",
    "\n",
    "First, a bit of theory. LDA is a generative model - a model over the entire data generating process - in which a document is a mixture of topics and topics are probability distributions over tokens in the vocabulary. The (normalized) frequency of word $j$ in document $i$ can be written as:\n",
    "$q_{ij} = v_{i1}*\\theta_{1j} + v_{i2}*\\theta_{2j} + ... + v_{iK}*\\theta_{Kj}$\n",
    "where K is the total number of topics, $\\theta_{kj}$ is the probability that word $j$ shows up in topic $k$ and $v_{ik}$ is the weight assigned to topic $k$ in document $i$. The model treats $v$ and $\\theta$ as generated from Dirichlet-distributed priors and can be estimated through Maximum Likelihood or Bayesian methods.\n",
    "\n",
    "Note: we will be using a different dataset for this technique. The music reviews in the above dataset are often short, one word or one sentence reviews. Topic modeling is not really appropriate for texts that are this short. Instead, we want texts that are longer and are composed of multiple topics each. For this exercise we will use a database of children's literature from the 19th century. \n",
    "\n",
    "The data were compiled by students in this course: http://english197s2015.pbworks.com/w/page/93127947/FrontPage\n",
    "Found here: http://dhresourcesforprojectbuilding.pbworks.com/w/page/69244469/Data%20Collections%20and%20Datasets#demo-corpora\n",
    "\n",
    "That page has additional corpora, for those interested in exploring text analysis further.\n",
    "\n",
    "$^1$ Reference: Blei, D. M., A. Y. Ng, and M. I. Jordan (2003). Latent Dirichlet allocation. Journal of Machine\n",
    "Learning Research 3, 993–1022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title author gender  year  \\\n",
       "0                          A Dog with a Bad Name          Male  1886   \n",
       "1                              A Final Reckoning          Male  1887   \n",
       "2  A House Party, Don Gesualdo, and A Rainy June        Female  1887   \n",
       "3                            A Houseful of Girls        Female  1889   \n",
       "4                          A Little Country Girl        Female  1885   \n",
       "\n",
       "                                                text  \n",
       "0  A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...  \n",
       "1  A Final Reckoning: A Tale of Bush Life in Aust...  \n",
       "2  A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...  \n",
       "3  A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...  \n",
       "4  LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literature_fname = os.path.join(DATA_DIR, 'childrens_lit.csv.bz2')\n",
    "df_lit = pd.read_csv(literature_fname, sep='\\t', encoding = 'utf-8', compression = 'bz2', index_col=0)\n",
    "\n",
    "#drop rows where the text is missing\n",
    "df_lit = df_lit.dropna(subset=['text'])\n",
    "df_lit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to fit the model. This requires the use of CountVectorizer, which we've already used, and the scikit-learn function LatentDirichletAllocation.\n",
    "\n",
    "See [here](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) for more information about this function. \n",
    "\n",
    "First, we have to import it from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, the input to LDA is a DTM (with either counts or TF-IDF scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gregor von Richthof\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.80, min_df=50,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(df_lit['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.80, min_df=50,\n",
    "                                stop_words='english'\n",
    "                                )\n",
    "tf = tf_vectorizer.fit_transform(df_lit['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "lda = LatentDirichletAllocation(n_topics=10, max_iter=20, random_state=0)\n",
    "lda = lda.fit(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to print out the top words for each topic in a pretty way. Don't worry too much about understanding every line of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #{}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "doctor girls papa mamma sister baby street aunt london sweet project tom dr tea study presently flower darling office everybody\n",
      "\n",
      "Topic #1:\n",
      "dick doctor uncle tom jack fish em lads rope rock birds shock beneath ay gun stream garden excitedly moments fishing\n",
      "\n",
      "Topic #2:\n",
      "french troops officers army attack guns officer tom soldiers regiment british camp village ship march jack fort wounded column native\n",
      "\n",
      "Topic #3:\n",
      "project doctor church ma mary gray girls thou works soldier regiment james rode public village officer george st cousin soldiers\n",
      "\n",
      "Topic #4:\n",
      "frank james king shore lake camp village forest boats coast attack troops french native fort woods stream ship army guns\n",
      "\n",
      "Topic #5:\n",
      "project ye works ship george foundation island shore em observed youth ice deck ay agreement vessel remarked crew fish considerable\n",
      "\n",
      "Topic #6:\n",
      "er uncle jack ain den yer wolf folks lion tail gun dish sing jump aunt study seed doctor bag goodness\n",
      "\n",
      "Topic #7:\n",
      "deck frank shore ship vessel boats island cabin sail lake passengers mate uncle officer bush port st south crew speed\n",
      "\n",
      "Topic #8:\n",
      "king prince john city army castle france sword attack soldiers palace troops queen french jack ship rode camp court numbers\n",
      "\n",
      "Topic #9:\n",
      "camp indian doctor ha arrows mountain rock em rode ride maiden pine band rocks mountains gun savage bushes deer cattle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Modify the script above to:\n",
    "* increase the number of topics\n",
    "* increase the number of printed top words per topic\n",
    "* fit the model to the tf-idf matrix instead of the tf one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic weights\n",
    "\n",
    "One thing we may want to do with the output is compare the prevalence of each topic across documents. A simple way to do this (but not memory efficient), is to merge the topic distribution back into the Pandas dataframe.\n",
    "\n",
    "First get the topic distribution array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.71598187e-01, 1.99211275e-02, 6.32910384e-02, ...,\n",
       "        1.25034836e-05, 3.79720913e-05, 4.40811557e-02],\n",
       "       [3.45023517e-02, 2.96151321e-02, 6.87865338e-02, ...,\n",
       "        7.16863274e-01, 1.37251101e-05, 1.17770974e-01],\n",
       "       [5.42918480e-01, 3.37979473e-03, 1.36686654e-05, ...,\n",
       "        1.36684699e-05, 3.64883088e-02, 1.36688476e-05],\n",
       "       ...,\n",
       "       [9.69609121e-06, 9.69620204e-06, 4.83220622e-03, ...,\n",
       "        9.69645662e-06, 9.93827250e-01, 1.27267072e-03],\n",
       "       [7.58453416e-06, 7.58455582e-06, 9.97801502e-01, ...,\n",
       "        7.58478411e-06, 7.58469156e-06, 7.58441317e-06],\n",
       "       [8.35441481e-06, 8.35426939e-06, 4.62466841e-01, ...,\n",
       "        3.46077391e-02, 8.35442365e-06, 8.35435389e-06]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dist = lda.transform(tf)\n",
    "topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge back with original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.871598</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.044081</td>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034502</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.068787</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.716863</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.117771</td>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542918</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.417131</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.036488</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984716</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.689145</td>\n",
       "      <td>0.049493</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.055327</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.811108</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.102136</td>\n",
       "      <td>A Round Dozen</td>\n",
       "      <td>Female</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>\\n A ROUND DOZEN.  [Illustration: TOINETTE AND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.430773</td>\n",
       "      <td>0.451863</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.111349</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>A Sailor's Lass</td>\n",
       "      <td>Female</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>A SAILOR'S LASS  by  EMMA LESLIE,  Author of \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.976862</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>A World of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>A WORLD OF GIRLS:  THE STORY OF A SCHOOL.  By ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.137004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.138041</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.724018</td>\n",
       "      <td>Adrift in the Wild</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>Adrift in the Wilds;          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.067510</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.872599</td>\n",
       "      <td>Adventures in Africa</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>ADVENTURES IN AFRICA, BY W.H.G. KINGSTON.    C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.146153</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.725855</td>\n",
       "      <td>Adventures in Australia</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>ADVENTURES IN AUSTRALIA, BY W.H.G. KINGSTON.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.998993</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>All Adrift</td>\n",
       "      <td>Male</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>ALL ADRIFT  OR  THE GOLDWING CLUB  BY  OLIVER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.972645</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.021455</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>Battles With the Sea</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>The Project Gutenberg EBook of Battles with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.312457</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.348916</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.100595</td>\n",
       "      <td>0.225510</td>\n",
       "      <td>Bimbi: Stories for Children</td>\n",
       "      <td>Female</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>Bimbi  Stories for Children  By Louise De La R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.924611</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>Blown To Bits; Or The Lonely Man of Rakata</td>\n",
       "      <td>Male</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>The Project Gutenberg EBook of Blown to Bits, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.072647</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.243649</td>\n",
       "      <td>0.017210</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Blue Lights Hot Work In the Soudan</td>\n",
       "      <td>Male</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>The Project Gutenberg EBook of Blue Lights, by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.326456</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.030711</td>\n",
       "      <td>0.642766</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Bonnie Prince Charlie</td>\n",
       "      <td>Male</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>Bonnie Prince Charlie  A Tale of Fontenoy and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.067881</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.928317</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>Breaking Away</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>BREAKING AWAY;  OR,  THE FORTUNES OF A STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.019853</td>\n",
       "      <td>0.971939</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>Brownsmith's Boy</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>Brownsmith's Boy, a Romance in a Garden, by Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.852211</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.147708</td>\n",
       "      <td>Bunyip Land</td>\n",
       "      <td>Male</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>BUNYIP LAND; A STORY OF ADVENTURE IN NEW GUINE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.131797</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.866879</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>By Sheer Pluck</td>\n",
       "      <td>Male</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>\\n BY SHEER PLUCK  A TALE OF THE ASHANTI WAR  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.044425</td>\n",
       "      <td>0.063946</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.211441</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.512951</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.096323</td>\n",
       "      <td>Captain Bayley's Heir</td>\n",
       "      <td>Male</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>CAPTAIN BAYLEY'S HEIR  A TALE OF THE GOLD FIEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.820773</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.038123</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.122846</td>\n",
       "      <td>Clover</td>\n",
       "      <td>Female</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>CLOVER  by  SUSAN COOLIDGE  Author of \"What Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.581939</td>\n",
       "      <td>0.069887</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.070314</td>\n",
       "      <td>0.277724</td>\n",
       "      <td>Crown and Sceptre</td>\n",
       "      <td>Male</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>CROWN AND SCEPTRE, A WEST COUNTRY STORY, BY GE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>Dick o' the Fens</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>DICK O' THE FENS; A TALE OF THE GREAT EASTERN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>Down South</td>\n",
       "      <td>Male</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>DOWN SOUTH OR YACHT ADVENTURES IN FLORIDA    B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.407307</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.571540</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>Dusty Diamonds Cut and Polished: A Tale of  Ci...</td>\n",
       "      <td>Male</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>Project Gutenberg's Dusty Diamonds Cut and Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.999866</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>Elsie's Kith and Kin</td>\n",
       "      <td>Female</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>The Project Gutenberg eBook, Elsie's Kith and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>Elsie's New Relations</td>\n",
       "      <td>Female</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>The Project Gutenberg eBook, Elsie's New Relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.146661</td>\n",
       "      <td>0.149473</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>0.323147</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.184974</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.184406</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>Facing Death</td>\n",
       "      <td>Male</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>FACING DEATH   OR,   THE HERO OF THE VAUGHAN P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>The Life of a Ship</td>\n",
       "      <td>Male</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Life of a S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.163371</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.019987</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.783503</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.024753</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>The Lion of Saint Mark</td>\n",
       "      <td>Male</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>THE LION OF ST. MARK:  A Story of Venice in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.052841</td>\n",
       "      <td>0.842399</td>\n",
       "      <td>0.028304</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.059157</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>The Lion of the North</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>THE LION OF THE NORTH  A Tale of the Times of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>The Little Princess of Tower Hill</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>THE LITTLE PRINCESS OF TOWER HILL.  BY L. T. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.527427</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.472441</td>\n",
       "      <td>The Lively Poll a Tale of the North Sea</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Lively Poll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.181616</td>\n",
       "      <td>0.103871</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.451252</td>\n",
       "      <td>0.252731</td>\n",
       "      <td>The Master of the Shell</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>THE MASTER OF THE SHELL  BY TALBOT BAINES REED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.639291</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.360612</td>\n",
       "      <td>The Middy and the Moors</td>\n",
       "      <td>Male</td>\n",
       "      <td>1888.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Middy and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.175848</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.824062</td>\n",
       "      <td>The New Forest Spy</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>The New Forest Spy, by George Manville Fenn.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.565456</td>\n",
       "      <td>0.073880</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.233775</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.126325</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>The Palace Beautiful</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>THE PALACE BEAUTIFUL.  A STORY FOR GIRLS.  BY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.035351</td>\n",
       "      <td>0.033901</td>\n",
       "      <td>0.098347</td>\n",
       "      <td>0.035966</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>The Prairie Chief</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Prairie Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.593276</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.383995</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>The Princess and Curdie</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>The Princess and Curdie   by  George MacDonald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.999296</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>The Red Man's Revenge A Tale of the Red River ...</td>\n",
       "      <td>Male</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Red Man's R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.943501</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.055257</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>The Silver Canyon</td>\n",
       "      <td>Male</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>THE SILVER CANYON, BY GEORGE MANVILLE FENN.   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.041379</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.946243</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>The Story of Patsy</td>\n",
       "      <td>Female</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>THE STORY OF PATSY  by  KATE DOUGLAS WIGGIN  A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.549076</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.426798</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>The Thorogood Family</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Thorogood F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.108234</td>\n",
       "      <td>0.852396</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.039285</td>\n",
       "      <td>The Twin Cousins</td>\n",
       "      <td>Female</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>The Project Gutenberg eBook, The Twin Cousins,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.093083</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.884188</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>The Two Elsies</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Two Elsies,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.967784</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.029953</td>\n",
       "      <td>The Willoughby Captains</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>THE WILLOUGHBY CAPTAINS  BY TALBOT BAINES REED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>The Young Buglers</td>\n",
       "      <td>Male</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>THE YOUNG BUGLERS  by G.A. Henty     PREFACE  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.361267</td>\n",
       "      <td>0.048289</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>0.413066</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.150890</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>The Young Carthaginian</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>THE YOUNG CARTHAGINIAN  A STORY OF THE TIMES O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.236688</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.157469</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.214998</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.387496</td>\n",
       "      <td>The Young Colonists</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>The Young Colonists A Story of the Zulu and Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.047459</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.596955</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.335630</td>\n",
       "      <td>The Young Trawler</td>\n",
       "      <td>Male</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>The Project Gutenberg EBook of The Young Trawl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>Three Boys</td>\n",
       "      <td>Male</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>Three Boys; or The Chiefs of the Clan Mackhai,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>Through Forest and Stream</td>\n",
       "      <td>Male</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>THROUGH FOREST AND STREAM; OR, THE QUEST OF TH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.656119</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>0.161643</td>\n",
       "      <td>0.076006</td>\n",
       "      <td>Through the Fray</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>THROUGH THE FRAY  A TALE OF THE LUDDITE RIOTS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>Treasure Island</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>TREASURE ISLAND  by Robert Louis Stevenson    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.876761</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.115557</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>Twice Bought</td>\n",
       "      <td>Male</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>The Project Gutenberg EBook of Twice Bought, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>Two Arrows</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>TWO ARROWS      HARPER'S YOUNG PEOPLE'S SERIES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>Uncle Remus: His Songs and Sayings</td>\n",
       "      <td>Male</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>Uncle Remus: His Songs and His Sayings  By Joe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.462467</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.502867</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.034608</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>Under Drake's Flag</td>\n",
       "      <td>Male</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>Under Drake's Flag:  A Tale of the Spanish Mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.871598  0.019921  0.063291  0.000013  0.000013  0.000013  0.001021   \n",
       "1    0.034502  0.029615  0.068787  0.030595  0.000014  0.000014  0.001825   \n",
       "2    0.542918  0.003380  0.000014  0.417131  0.000014  0.000014  0.000014   \n",
       "3    0.984716  0.000012  0.000012  0.005849  0.000012  0.000012  0.000012   \n",
       "4    0.689145  0.049493  0.000022  0.205900  0.000022  0.000022  0.000022   \n",
       "5    0.811108  0.086477  0.000023  0.000141  0.000023  0.000023  0.000023   \n",
       "6    0.430773  0.451863  0.000051  0.000051  0.000051  0.005707  0.111349   \n",
       "7    0.976862  0.000014  0.000014  0.000014  0.007139  0.000014  0.000014   \n",
       "8    0.000017  0.000017  0.000017  0.000017  0.000834  0.137004  0.000017   \n",
       "9    0.000027  0.000027  0.067510  0.000027  0.000027  0.000027  0.059704   \n",
       "10   0.000030  0.000030  0.127779  0.000030  0.000030  0.000030  0.000030   \n",
       "11   0.000021  0.000842  0.000021  0.000021  0.000021  0.000021  0.000021   \n",
       "12   0.000028  0.000028  0.005702  0.000028  0.000028  0.972645  0.000028   \n",
       "13   0.312457  0.012394  0.000026  0.348916  0.000026  0.000026  0.000026   \n",
       "14   0.000671  0.000008  0.003889  0.000008  0.032399  0.924611  0.000008   \n",
       "15   0.072647  0.000010  0.243649  0.017210  0.000010  0.665678  0.000765   \n",
       "16   0.000010  0.000010  0.326456  0.000010  0.000010  0.000010  0.000010   \n",
       "17   0.067881  0.000017  0.000017  0.000017  0.000017  0.003679  0.000017   \n",
       "18   0.019853  0.971939  0.000011  0.005379  0.000011  0.000011  0.002760   \n",
       "19   0.000010  0.852211  0.000010  0.000010  0.000010  0.000010  0.000010   \n",
       "20   0.000010  0.001253  0.131797  0.000010  0.866879  0.000010  0.000010   \n",
       "21   0.044425  0.063946  0.000010  0.048374  0.211441  0.000010  0.022510   \n",
       "22   0.820773  0.000023  0.000023  0.038123  0.000023  0.000023  0.000023   \n",
       "23   0.000090  0.581939  0.069887  0.000009  0.000009  0.000009  0.000009   \n",
       "24   0.000008  0.999924  0.000008  0.000008  0.000008  0.000008  0.000008   \n",
       "25   0.000019  0.000019  0.000019  0.000019  0.000019  0.000019  0.000019   \n",
       "26   0.407307  0.000011  0.000011  0.017114  0.000011  0.571540  0.003974   \n",
       "27   0.999866  0.000015  0.000015  0.000015  0.000015  0.000015  0.000015   \n",
       "28   0.999856  0.000016  0.000016  0.000016  0.000016  0.000016  0.000016   \n",
       "29   0.146661  0.149473  0.010264  0.323147  0.000015  0.001029  0.184974   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "97   0.999892  0.000012  0.000012  0.000012  0.000012  0.000012  0.000012   \n",
       "98   0.163371  0.000017  0.019987  0.000017  0.000017  0.783503  0.008300   \n",
       "99   0.052841  0.842399  0.028304  0.000033  0.011843  0.000033  0.005322   \n",
       "100  0.999884  0.000013  0.000013  0.000013  0.000013  0.000013  0.000013   \n",
       "101  0.000017  0.000017  0.000017  0.000017  0.000017  0.527427  0.000017   \n",
       "102  0.181616  0.103871  0.000022  0.010418  0.000022  0.000022  0.000022   \n",
       "103  0.000012  0.000012  0.000012  0.000012  0.000012  0.639291  0.000012   \n",
       "104  0.000011  0.175848  0.000011  0.000011  0.000011  0.000011  0.000011   \n",
       "105  0.565456  0.073880  0.000094  0.233775  0.000094  0.000094  0.126325   \n",
       "106  0.035351  0.033901  0.098347  0.035966  0.000036  0.782283  0.000036   \n",
       "107  0.593276  0.000034  0.000034  0.383995  0.000034  0.000034  0.022489   \n",
       "108  0.999296  0.000016  0.000016  0.000016  0.000016  0.000572  0.000016   \n",
       "109  0.943501  0.000010  0.000010  0.000010  0.000010  0.000010  0.000010   \n",
       "110  0.041379  0.010681  0.946243  0.000010  0.000010  0.000010  0.001638   \n",
       "111  0.000008  0.000008  0.549076  0.000008  0.000008  0.000008  0.000008   \n",
       "112  0.000012  0.108234  0.852396  0.000012  0.000012  0.000012  0.000012   \n",
       "113  0.093083  0.003341  0.000011  0.000011  0.000011  0.884188  0.004432   \n",
       "114  0.000013  0.967784  0.000013  0.000013  0.000013  0.002172  0.000013   \n",
       "115  0.000031  0.911250  0.000031  0.000031  0.000031  0.000031  0.000031   \n",
       "116  0.361267  0.048289  0.016314  0.413066  0.000013  0.000013  0.000013   \n",
       "117  0.001960  0.236688  0.000016  0.001325  0.000016  0.157469  0.000016   \n",
       "118  0.000616  0.047459  0.017746  0.000013  0.000013  0.596955  0.001543   \n",
       "119  0.000018  0.000018  0.000018  0.000018  0.000018  0.000018  0.000018   \n",
       "120  0.000021  0.000021  0.000021  0.000021  0.000021  0.000021  0.999807   \n",
       "121  0.000008  0.000008  0.656119  0.000008  0.000096  0.001124  0.000008   \n",
       "122  0.000018  0.000018  0.000018  0.000018  0.000018  0.000018  0.000018   \n",
       "123  0.876761  0.000020  0.004370  0.003192  0.000020  0.000020  0.000020   \n",
       "124  0.000010  0.000010  0.004832  0.000010  0.000010  0.000010  0.000010   \n",
       "125  0.000008  0.000008  0.997802  0.000008  0.000008  0.000008  0.002138   \n",
       "126  0.000008  0.000008  0.462467  0.000008  0.502867  0.000008  0.000008   \n",
       "\n",
       "            7         8         9  \\\n",
       "0    0.000013  0.000038  0.044081   \n",
       "1    0.716863  0.000014  0.117771   \n",
       "2    0.000014  0.036488  0.000014   \n",
       "3    0.003454  0.005911  0.000012   \n",
       "4    0.055327  0.000022  0.000022   \n",
       "5    0.000023  0.000023  0.102136   \n",
       "6    0.000051  0.000051  0.000051   \n",
       "7    0.000014  0.015903  0.000014   \n",
       "8    0.138041  0.000017  0.724018   \n",
       "9    0.000027  0.000027  0.872599   \n",
       "10   0.146153  0.000030  0.725855   \n",
       "11   0.998993  0.000021  0.000021   \n",
       "12   0.021455  0.000028  0.000028   \n",
       "13   0.000026  0.100595  0.225510   \n",
       "14   0.004877  0.008679  0.024848   \n",
       "15   0.000010  0.000010  0.000010   \n",
       "16   0.030711  0.642766  0.000010   \n",
       "17   0.928317  0.000017  0.000017   \n",
       "18   0.000011  0.000011  0.000011   \n",
       "19   0.000010  0.000010  0.147708   \n",
       "20   0.000010  0.000010  0.000010   \n",
       "21   0.512951  0.000010  0.096323   \n",
       "22   0.018120  0.000023  0.122846   \n",
       "23   0.000009  0.070314  0.277724   \n",
       "24   0.000008  0.000008  0.000008   \n",
       "25   0.999833  0.000019  0.000019   \n",
       "26   0.000011  0.000011  0.000011   \n",
       "27   0.000015  0.000015  0.000015   \n",
       "28   0.000016  0.000016  0.000016   \n",
       "29   0.000015  0.184406  0.000015   \n",
       "..        ...       ...       ...   \n",
       "97   0.000012  0.000012  0.000012   \n",
       "98   0.000017  0.024753  0.000017   \n",
       "99   0.000033  0.059157  0.000033   \n",
       "100  0.000013  0.000013  0.000013   \n",
       "101  0.000017  0.000017  0.472441   \n",
       "102  0.000022  0.451252  0.252731   \n",
       "103  0.000012  0.000012  0.360612   \n",
       "104  0.000011  0.000011  0.824062   \n",
       "105  0.000094  0.000094  0.000094   \n",
       "106  0.000036  0.000036  0.014006   \n",
       "107  0.000034  0.000034  0.000034   \n",
       "108  0.000016  0.000016  0.000016   \n",
       "109  0.001169  0.055257  0.000010   \n",
       "110  0.000010  0.000010  0.000010   \n",
       "111  0.000008  0.426798  0.024070   \n",
       "112  0.000012  0.000012  0.039285   \n",
       "113  0.014899  0.000011  0.000011   \n",
       "114  0.000013  0.000013  0.029953   \n",
       "115  0.000031  0.000031  0.088500   \n",
       "116  0.010119  0.150890  0.000013   \n",
       "117  0.214998  0.000016  0.387496   \n",
       "118  0.000013  0.000013  0.335630   \n",
       "119  0.000018  0.000018  0.999835   \n",
       "120  0.000021  0.000021  0.000021   \n",
       "121  0.104979  0.161643  0.076006   \n",
       "122  0.999840  0.000018  0.000018   \n",
       "123  0.115557  0.000020  0.000020   \n",
       "124  0.000010  0.993827  0.001273   \n",
       "125  0.000008  0.000008  0.000008   \n",
       "126  0.034608  0.000008  0.000008   \n",
       "\n",
       "                                                 title author gender    year  \\\n",
       "0                                A Dog with a Bad Name          Male  1886.0   \n",
       "1                                    A Final Reckoning          Male  1887.0   \n",
       "2        A House Party, Don Gesualdo, and A Rainy June        Female  1887.0   \n",
       "3                                  A Houseful of Girls        Female  1889.0   \n",
       "4                                A Little Country Girl        Female  1885.0   \n",
       "5                                        A Round Dozen        Female  1883.0   \n",
       "6                                      A Sailor's Lass        Female  1886.0   \n",
       "7                                     A World of Girls        Female  1886.0   \n",
       "8                                   Adrift in the Wild          Male  1887.0   \n",
       "9                                 Adventures in Africa          Male  1883.0   \n",
       "10                             Adventures in Australia          Male  1885.0   \n",
       "11                                          All Adrift          Male  1882.0   \n",
       "12                                Battles With the Sea          Male  1883.0   \n",
       "13                         Bimbi: Stories for Children        Female  1882.0   \n",
       "14          Blown To Bits; Or The Lonely Man of Rakata          Male  1889.0   \n",
       "15                  Blue Lights Hot Work In the Soudan          Male  1888.0   \n",
       "16                               Bonnie Prince Charlie          Male  1888.0   \n",
       "17                                       Breaking Away          Male  1887.0   \n",
       "18                                    Brownsmith's Boy          Male  1886.0   \n",
       "19                                         Bunyip Land          Male  1880.0   \n",
       "20                                      By Sheer Pluck          Male  1884.0   \n",
       "21                               Captain Bayley's Heir          Male  1889.0   \n",
       "22                                              Clover        Female  1888.0   \n",
       "23                                   Crown and Sceptre          Male  1889.0   \n",
       "24                                    Dick o' the Fens          Male  1885.0   \n",
       "25                                          Down South          Male  1880.0   \n",
       "26   Dusty Diamonds Cut and Polished: A Tale of  Ci...          Male  1884.0   \n",
       "27                                Elsie's Kith and Kin        Female  1886.0   \n",
       "28                               Elsie's New Relations        Female  1883.0   \n",
       "29                                        Facing Death          Male  1882.0   \n",
       "..                                                 ...           ...     ...   \n",
       "97                                  The Life of a Ship          Male  1882.0   \n",
       "98                              The Lion of Saint Mark          Male  1889.0   \n",
       "99                               The Lion of the North          Male  1886.0   \n",
       "100                  The Little Princess of Tower Hill        Female  1889.0   \n",
       "101            The Lively Poll a Tale of the North Sea          Male  1886.0   \n",
       "102                            The Master of the Shell          Male  1887.0   \n",
       "103                            The Middy and the Moors          Male  1888.0   \n",
       "104                                 The New Forest Spy          Male  1885.0   \n",
       "105                               The Palace Beautiful        Female  1887.0   \n",
       "106                                  The Prairie Chief          Male  1886.0   \n",
       "107                            The Princess and Curdie          Male  1883.0   \n",
       "108  The Red Man's Revenge A Tale of the Red River ...          Male  1880.0   \n",
       "109                                  The Silver Canyon          Male  1884.0   \n",
       "110                                 The Story of Patsy        Female  1883.0   \n",
       "111                               The Thorogood Family          Male  1883.0   \n",
       "112                                   The Twin Cousins        Female  1880.0   \n",
       "113                                     The Two Elsies        Female  1885.0   \n",
       "114                            The Willoughby Captains          Male  1883.0   \n",
       "115                                  The Young Buglers          Male  1880.0   \n",
       "116                             The Young Carthaginian          Male  1887.0   \n",
       "117                                The Young Colonists          Male  1885.0   \n",
       "118                                  The Young Trawler          Male  1884.0   \n",
       "119                                         Three Boys          Male  1889.0   \n",
       "120                          Through Forest and Stream          Male  1884.0   \n",
       "121                                   Through the Fray          Male  1886.0   \n",
       "122                                    Treasure Island          Male  1883.0   \n",
       "123                                       Twice Bought          Male  1885.0   \n",
       "124                                         Two Arrows          Male  1886.0   \n",
       "125                 Uncle Remus: His Songs and Sayings          Male  1880.0   \n",
       "126                                 Under Drake's Flag          Male  1883.0   \n",
       "\n",
       "                                                  text  \n",
       "0    A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...  \n",
       "1    A Final Reckoning: A Tale of Bush Life in Aust...  \n",
       "2    A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...  \n",
       "3    A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...  \n",
       "4    LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...  \n",
       "5    \\n A ROUND DOZEN.  [Illustration: TOINETTE AND...  \n",
       "6    A SAILOR'S LASS  by  EMMA LESLIE,  Author of \"...  \n",
       "7    A WORLD OF GIRLS:  THE STORY OF A SCHOOL.  By ...  \n",
       "8                    Adrift in the Wilds;          ...  \n",
       "9    ADVENTURES IN AFRICA, BY W.H.G. KINGSTON.    C...  \n",
       "10   ADVENTURES IN AUSTRALIA, BY W.H.G. KINGSTON.  ...  \n",
       "11   ALL ADRIFT  OR  THE GOLDWING CLUB  BY  OLIVER ...  \n",
       "12   The Project Gutenberg EBook of Battles with th...  \n",
       "13   Bimbi  Stories for Children  By Louise De La R...  \n",
       "14   The Project Gutenberg EBook of Blown to Bits, ...  \n",
       "15   The Project Gutenberg EBook of Blue Lights, by...  \n",
       "16   Bonnie Prince Charlie  A Tale of Fontenoy and ...  \n",
       "17   BREAKING AWAY;  OR,  THE FORTUNES OF A STUDENT...  \n",
       "18   Brownsmith's Boy, a Romance in a Garden, by Ge...  \n",
       "19   BUNYIP LAND; A STORY OF ADVENTURE IN NEW GUINE...  \n",
       "20   \\n BY SHEER PLUCK  A TALE OF THE ASHANTI WAR  ...  \n",
       "21   CAPTAIN BAYLEY'S HEIR  A TALE OF THE GOLD FIEL...  \n",
       "22   CLOVER  by  SUSAN COOLIDGE  Author of \"What Ka...  \n",
       "23   CROWN AND SCEPTRE, A WEST COUNTRY STORY, BY GE...  \n",
       "24   DICK O' THE FENS; A TALE OF THE GREAT EASTERN ...  \n",
       "25   DOWN SOUTH OR YACHT ADVENTURES IN FLORIDA    B...  \n",
       "26   Project Gutenberg's Dusty Diamonds Cut and Pol...  \n",
       "27   The Project Gutenberg eBook, Elsie's Kith and ...  \n",
       "28   The Project Gutenberg eBook, Elsie's New Relat...  \n",
       "29   FACING DEATH   OR,   THE HERO OF THE VAUGHAN P...  \n",
       "..                                                 ...  \n",
       "97   The Project Gutenberg EBook of The Life of a S...  \n",
       "98   THE LION OF ST. MARK:  A Story of Venice in th...  \n",
       "99   THE LION OF THE NORTH  A Tale of the Times of ...  \n",
       "100  THE LITTLE PRINCESS OF TOWER HILL.  BY L. T. M...  \n",
       "101  The Project Gutenberg EBook of The Lively Poll...  \n",
       "102  THE MASTER OF THE SHELL  BY TALBOT BAINES REED...  \n",
       "103  The Project Gutenberg EBook of The Middy and t...  \n",
       "104  The New Forest Spy, by George Manville Fenn.  ...  \n",
       "105  THE PALACE BEAUTIFUL.  A STORY FOR GIRLS.  BY ...  \n",
       "106  The Project Gutenberg EBook of The Prairie Chi...  \n",
       "107  The Princess and Curdie   by  George MacDonald...  \n",
       "108  The Project Gutenberg EBook of The Red Man's R...  \n",
       "109  THE SILVER CANYON, BY GEORGE MANVILLE FENN.   ...  \n",
       "110  THE STORY OF PATSY  by  KATE DOUGLAS WIGGIN  A...  \n",
       "111  The Project Gutenberg EBook of The Thorogood F...  \n",
       "112  The Project Gutenberg eBook, The Twin Cousins,...  \n",
       "113  The Project Gutenberg EBook of The Two Elsies,...  \n",
       "114  THE WILLOUGHBY CAPTAINS  BY TALBOT BAINES REED...  \n",
       "115  THE YOUNG BUGLERS  by G.A. Henty     PREFACE  ...  \n",
       "116  THE YOUNG CARTHAGINIAN  A STORY OF THE TIMES O...  \n",
       "117  The Young Colonists A Story of the Zulu and Bo...  \n",
       "118  The Project Gutenberg EBook of The Young Trawl...  \n",
       "119  Three Boys; or The Chiefs of the Clan Mackhai,...  \n",
       "120  THROUGH FOREST AND STREAM; OR, THE QUEST OF TH...  \n",
       "121  THROUGH THE FRAY  A TALE OF THE LUDDITE RIOTS ...  \n",
       "122  TREASURE ISLAND  by Robert Louis Stevenson    ...  \n",
       "123  The Project Gutenberg EBook of Twice Bought, b...  \n",
       "124  TWO ARROWS      HARPER'S YOUNG PEOPLE'S SERIES...  \n",
       "125  Uncle Remus: His Songs and His Sayings  By Joe...  \n",
       "126  Under Drake's Flag:  A Tale of the Spanish Mai...  \n",
       "\n",
       "[127 rows x 14 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dist_df = pd.DataFrame(topic_dist)\n",
    "df_w_topics = topic_dist_df.join(df_lit)\n",
    "df_w_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can chech the average weight of each topic across gender using `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author gender\n",
       "Female    0.529574\n",
       "Male      0.174689\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_w_topics.groupby('author gender')\n",
    "grouped[0].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA as dimensionality reduction\n",
    "\n",
    "Now that we obtained a distribution of topic weights for each document, we can represent our corpus with a dense document-weight matrix as opposed to our initial sparse DTM. The weights can then replace tokens as features for any subsequent task (classification, prediction, etc). A simple example may consist in measuring cosine similarity between documents. For instance, which book is closest to the first book in our corpus? Let's use pairwise cosine similarity to find out. \n",
    "\n",
    "NB: cosine similarity measures an angle between two vectors, which provides a measure of distance robust to vectors of different lenghts (total number of tokens)\n",
    "\n",
    "First, let's turn the DTM into a readable dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(tf_vectorizer.fit_transform(df_lit['text']).toarray(), columns=tf_vectorizer.get_feature_names(), index = df_lit.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's import the cosine_similarity function from sklearn and print the cosine similarity between the first and second book or the first and third book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between first and second book: [[0.28012828]]\n",
      "Cosine similarity between first and third book: [[0.40808192]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"Cosine similarity between first and second book: \" + str(cosine_similarity(dtm.iloc[0,:], dtm.iloc[1,:])))\n",
    "print(\"Cosine similarity between first and third book: \" + str(cosine_similarity(dtm.iloc[0,:], dtm.iloc[2,:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use the topic weights instead of word frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between first and second book: [[0.06279451]]\n",
      "Cosine similarity between first and third book: [[0.78868067]]\n"
     ]
    }
   ],
   "source": [
    "dwm = df_w_topics.iloc[:,:10]\n",
    "\n",
    "print(\"Cosine similarity between first and second book: \" + str(cosine_similarity(dwm.iloc[0,:], dwm.iloc[1,:])))\n",
    "print(\"Cosine similarity between first and third book: \" + str(cosine_similarity(dwm.iloc[0,:], dwm.iloc[2,:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge - SOLUTION\n",
    "\n",
    "Calculate the cosine similarity between the first book and all other books to identify the most similar one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max similarity: 0.9963235428011331\n",
      "Index of most similar book: 43\n",
      "Title of most similar book: Jo's Boys\n"
     ]
    }
   ],
   "source": [
    "sim = cosine_similarity(dwm.iloc[0,:], dwm.iloc[1,:]) #cosine similarity with 2nd book\n",
    "for i in range(2, len(dwm)):\n",
    "    sim = np.append(sim, cosine_similarity(dwm.iloc[0,:], dwm.iloc[i,:])) #append cosine similarity with i'th book\n",
    "print(\"Max similarity: \" + str(np.max(sim)))\n",
    "print(\"Index of most similar book: \" + str(np.argmax(sim)+1))\n",
    "print(\"Title of most similar book: \" + df_lit['title'][np.argmax(sim)+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further resources\n",
    "\n",
    "[This blog post](https://de.dariah.eu/tatom/feature_selection.html) goes through finding distinctive words using Python in more detail \n",
    "\n",
    "Paper: [Fightin’ Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict](http://languagelog.ldc.upenn.edu/myl/Monroe.pdf), Burt Monroe, Michael Colaresi, Kevin Quinn\n",
    "\n",
    "[Topic modeling with Textacy](https://github.com/repmax/topic-model/blob/master/topic-modelling.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
